# RADAR: Reasoning and Artifact Detection Module

Deep learning model for deepfake detection using dual artifact detection (boundary + frequency) with evidence-based reasoning.

## ğŸš€ Quick Start

### 1. Setup Environment
```bash
pip install torch torchvision timm albumentations datasets pillow tqdm scikit-learn pyyaml opencv-python
```

### 2. Download FaceForensics++ (Recommended)
```bash
# Test with sample data (~10 minutes)
python 0_download_faceforensics.py --sample_only --skip_test

# Or full dataset (~130GB, run overnight)
python 0_download_faceforensics.py
```

### 3. Prepare Dataset
```bash
python src/data/prepare_faceforensics.py \
  --video_dir ./data/faceforensics \
  --output_dir ./data/faceforensics_frames
```

### 4. Train Model
```bash
# Quick test (5 epochs)
python 2_train_model_fast.py \
  --data_dir ./data/faceforensics_frames \
  --experiment_name radar_test

# Full training (30 epochs)
python 2_train_model.py \
  --data_dir ./data/faceforensics_frames \
  --experiment_name radar_full
```

## ğŸ“Š Model Architecture

RADAR consists of three key components:

1. **BADM (Boundary Artifact Detection Module)**
   - Detects manipulation artifacts at face boundaries
   - Uses Sobel edge detection + CNN encoder

2. **AADM (Frequency Artifact Detection Module)**
   - Analyzes frequency domain anomalies
   - On-the-fly FFT computation for distribution consistency

3. **ERM (Evidence Refinement Module)**
   - Iterative reasoning with GRU + cross-attention
   - Fuses evidence from BADM and AADM

## ğŸ“ Project Structure

```
RADAR/
â”œâ”€â”€ 0_download_faceforensics.py    # Download FaceForensics++
â”œâ”€â”€ 2_train_model.py               # Full training
â”œâ”€â”€ 2_train_model_fast.py          # Fast training (subset)
â”œâ”€â”€ 3_export_results.py            # Package results
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ method/
â”‚   â”‚   â”œâ”€â”€ radar.py               # Main RADAR model
â”‚   â”‚   â”œâ”€â”€ boundary.py            # BADM implementation
â”‚   â”‚   â”œâ”€â”€ frequency.py           # AADM implementation
â”‚   â”‚   â”œâ”€â”€ reasoning.py           # ERM implementation
â”‚   â”‚   â””â”€â”€ loss.py                # Multi-task loss
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ prepare_faceforensics.py  # Frame extraction
â”‚   â”‚   â”œâ”€â”€ dataset.py             # PyTorch dataset
â”‚   â”‚   â””â”€â”€ splits.py              # Data splitting
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logging.py             # Clean logging utilities
â””â”€â”€ FACEFORENSICS_GUIDE.md        # Detailed FF++ guide
```

## ğŸ¯ Training Options

### Fast Mode (Testing)
```bash
python 2_train_model_fast.py \
  --data_dir ./data/faceforensics_frames \
  --batch_size 32 \
  --num_epochs 5
```

### Full Mode (Research)
```bash
python 2_train_model.py \
  --data_dir ./data/faceforensics_frames \
  --batch_size 64 \
  --num_epochs 30 \
  --learning_rate 0.0005
```

## ğŸ“ˆ Expected Results

**FaceForensics++ (c23):**
- Deepfakes: 95%+ AUC
- Face2Face: 92%+ AUC
- FaceSwap: 94%+ AUC
- NeuralTextures: 90%+ AUC
- **Average: 93%+ AUC**

## ğŸ”¬ For Research Papers

1. **Dataset:** FaceForensics++ (standard benchmark)
2. **Training:** Use `2_train_model.py` with default config
3. **Evaluation:** Per-manipulation + cross-dataset (Celeb-DF)
4. **Ablations:** BADM-only, AADM-only, Full RADAR

See `FACEFORENSICS_GUIDE.md` for detailed research setup.

## ğŸ“ Citation

If you use RADAR in your research, please cite:

```bibtex
@article{radar2024,
  title={RADAR: Reasoning and Artifact Detection for Deepfake Recognition},
  author={Your Name},
  journal={arXiv preprint},
  year={2024}
}
```

## ğŸ› ï¸ Code Quality

This codebase follows clean-code principles:
- Single Responsibility Principle (SRP)
- DRY (Don't Repeat Yourself)
- Small functions (<20 lines)
- Clear naming conventions
- Minimal comments (self-documenting code)

## ğŸ“– Documentation

- `FACEFORENSICS_GUIDE.md` - Complete FF++ pipeline guide
- `src/method/` - Model architecture documentation
- Clean code examples throughout

## ğŸ› Troubleshooting

See `FACEFORENSICS_GUIDE.md` troubleshooting section.

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- FaceForensics++ dataset team
- PyTorch and timm libraries
- Vision Transformer (ViT) backbone
