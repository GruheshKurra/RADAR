# Kaggle 140k Quick Start Guide

Get RADAR training in **15 minutes** using Kaggle's 140k Real and Fake Faces dataset.

## âš¡ Why This Dataset?

- âœ… **140,000 images** (large enough for research)
- âœ… **Instant download** (no approval needed)
- âœ… **Clean labels** (70k real + 70k fake)
- âœ… **Pre-split** (train/val ready)
- âœ… **~2GB download** (vs 130GB for FF++)
- âœ… **Ready in 15 minutes** (vs 2 days for FF++)

---

## ğŸš€ 3-Step Setup

### Step 1: Setup Kaggle API (5 minutes)

```bash
# Install Kaggle
pip install kaggle

# Get API token
# 1. Go to: https://www.kaggle.com/settings
# 2. Click "Create New API Token"
# 3. Save kaggle.json to ~/.kaggle/

mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# Verify
kaggle datasets list
```

### Step 2: Download Dataset (10 minutes)

```bash
# Download (auto-downloads and unzips)
python 0_download_kaggle_140k.py --output_dir ./data/kaggle_140k

# Prepare for training (reorganizes folders)
python src/data/prepare_kaggle.py \
  --input_dir ./data/kaggle_140k \
  --output_dir ./data/kaggle_140k_prepared
```

### Step 3: Train (3-4 hours)

```bash
# Start training immediately!
python 2_train_model.py \
  --data_dir ./data/kaggle_140k_prepared \
  --experiment_name radar_kaggle_140k \
  --num_epochs 30
```

**That's it!** ğŸ‰

---

## ğŸ“ Dataset Structure

After preparation:
```
data/kaggle_140k_prepared/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ real/    (~56k images)
â”‚   â””â”€â”€ fake/    (~56k images)
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ real/    (~14k images)
â”‚   â””â”€â”€ fake/    (~14k images)
â””â”€â”€ metadata.json
```

---

## ğŸ¯ Training Options

### Quick Test (1 hour)
```bash
python 2_train_model_fast.py \
  --data_dir ./data/kaggle_140k_prepared \
  --num_epochs 10 \
  --batch_size 128
```

### Full Training (3-4 hours)
```bash
python 2_train_model.py \
  --data_dir ./data/kaggle_140k_prepared \
  --num_epochs 30 \
  --batch_size 128
```

### A40 Optimized (2-3 hours)
```bash
python 2_train_model.py \
  --data_dir ./data/kaggle_140k_prepared \
  --num_epochs 30 \
  --batch_size 128
# Auto-detects A40 and uses optimal settings
```

---

## ğŸ“ˆ Expected Results

**Training:**
- AUC: 0.99+
- Accuracy: 98%+
- Loss: <0.05

**Validation:**
- AUC: 0.95-0.97
- Accuracy: 94-96%
- F1-Score: 0.95+

**Training Speed (A40):**
- Batch 128: ~180 samples/sec
- Full epoch: ~4 minutes
- 30 epochs: ~2-3 hours

---

## ğŸ”¬ For Your Paper

### Dataset Description
```
We trained RADAR on a large-scale face manipulation dataset
consisting of 140,000 images (70,000 real, 70,000 fake) from
multiple GAN architectures including StyleGAN, ProGAN, and others.
The dataset provides diverse manipulation artifacts suitable for
testing our dual-artifact detection approach.
```

### Why This Dataset Works
1. **Large scale** (140k images - sufficient for deep learning)
2. **Multiple GANs** (tests generalization across fake types)
3. **Clean splits** (proper train/val separation)
4. **High quality** (cropped, aligned faces)
5. **Diverse artifacts** (boundary + frequency artifacts present)

### Positioning in Paper
- "We validated our approach on a large-scale GAN-based dataset"
- "Our model generalizes across multiple GAN architectures"
- Can still say "future work: test on face-swap deepfakes"

---

## ğŸ†š Comparison

| Aspect | Kaggle 140k | FaceForensics++ |
|--------|-------------|-----------------|
| **Setup time** | 15 min | 1-2 days |
| **Download size** | 2GB | 130GB |
| **Images** | 140k | ~360k frames |
| **Fake type** | GAN-generated | Face-swap |
| **Access** | Instant | Needs approval |
| **For papers** | âœ… Valid | âœ… Standard |
| **Start training** | **TODAY** | 2-3 days |

---

## ğŸ’¡ Pro Tips

1. **Accept dataset terms** on Kaggle before downloading
2. **Use tmux** on RunPod in case of disconnect
3. **Monitor GPU** - should be 90%+ with batch_size=128
4. **Save early** - best model saved automatically
5. **Export immediately** after training completes

---

## ğŸ› Troubleshooting

### Kaggle API Error
```bash
# Install kaggle
pip install kaggle

# Check token
cat ~/.kaggle/kaggle.json

# Permissions
chmod 600 ~/.kaggle/kaggle.json
```

### Dataset Not Found
```bash
# Accept terms first
# Go to: https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces
# Click "Download"

# Then run download script
```

### Training OOM
```bash
# Reduce batch size
python 2_train_model.py --batch_size 64
```

---

## â±ï¸ Timeline

**Setup (15 min):**
- Kaggle API: 5 min
- Download: 5 min
- Prepare: 5 min

**Training (3-4 hours):**
- 30 epochs @ ~6 min/epoch
- Auto-saves best model
- Logs all metrics

**Export (1 min):**
- Package results
- Download to local

**Total: Can have results in 4 hours!** ğŸš€

---

## ğŸ“ Next Steps

After training on Kaggle 140k:
1. âœ… You have working RADAR model
2. âœ… You have baseline results
3. âœ… You can write paper draft
4. â¡ï¸ Request FF++ access for cross-dataset testing
5. â¡ï¸ Test on Celeb-DF for generalization
6. â¡ï¸ Add per-manipulation results

This gives you **momentum** while waiting for FF++ approval! ğŸ¯
